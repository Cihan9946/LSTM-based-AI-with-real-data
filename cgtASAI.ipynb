{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dropout\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Verileri yükle\n",
        "data = pd.read_excel(\"train.xlsx\")\n",
        "data = data.drop([\"id\", \"temp\", \"w_status\"], axis=1)\n",
        "\n",
        "# 'date' sütununu datetime formatına çevirme\n",
        "data['date_v'] = pd.to_datetime(data['date_v'])\n",
        "\n",
        "# 'date' sütununu Unix zaman damgasına çevirme\n",
        "data['unix_time'] = data['date_v'].apply(lambda x: int((x - datetime(1970, 1, 1)).total_seconds()))\n",
        "\n",
        "# Gereksiz sütunu ve orijinal tarih sütununu kaldırma\n",
        "data = data.drop([\"date_v\"], axis=1)\n",
        "\n",
        "# MinMaxScaler ile 'yukh', 'reg' ve 'power' sütunlarını ölçeklendirme\n",
        "scaler_yukh = MinMaxScaler()\n",
        "scaler_reg = MinMaxScaler()\n",
        "scaler_power = MinMaxScaler()\n",
        "\n",
        "data['yukh_scaled'] = scaler_yukh.fit_transform(data[['yukh']])\n",
        "data['reg_scaled'] = scaler_reg.fit_transform(data[['reg']])\n",
        "data['power_scaled'] = scaler_power.fit_transform(data[['power']])\n",
        "\n",
        "# Ölçeklenmiş sütunları veriden kaldırma\n",
        "data = data.drop([\"yukh\", \"reg\", \"power\"], axis=1)\n",
        "\n",
        "# Zaman serisi formatına dönüştürme\n",
        "def create_time_series_data(data, window_size):\n",
        "    X, y = [], []\n",
        "\n",
        "    for i in range(len(data) - window_size):\n",
        "        # Pencere boyutu kadar veriyi seçme\n",
        "        window_yukh = data['yukh_scaled'][i:i+window_size].values\n",
        "        window_reg = data['reg_scaled'][i:i+window_size].values\n",
        "        window_power = data['power_scaled'][i:i+window_size].values\n",
        "        target = data['yukh_scaled'][i + window_size]\n",
        "\n",
        "        X.append(np.column_stack((window_yukh, window_reg, window_power)))\n",
        "        y.append(target)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Pencere boyutunu belirleme\n",
        "window_size = 64\n",
        "\n",
        "# Giriş ve hedef verilerini oluşturma\n",
        "X, y = create_time_series_data(data, window_size)\n",
        "\n",
        "# Veriyi eğitim ve test setlerine ayırma\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "# Modeli oluşturma\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(LSTM(units=50, activation='relu', return_sequences=True))\n",
        "model.add(LSTM(units=50, activation='relu'))\n",
        "model.add(Dropout(0.2))  # Dropout katmanı eklendi\n",
        "model.add(Dense(units=1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Modeli eğitme\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "# Test seti üzerinde tahmin yapma\n",
        "test_predictions = model.predict(X_test)\n",
        "r2_test = r2_score(y_test, test_predictions)\n",
        "\n",
        "print(f'Modelin Test R-kare skoru: {r2_test}')\n"
      ],
      "metadata": {
        "id": "sVYEG3yPhqkO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7076cb2-0167-4b64-f344-d3a14f30b822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "144/144 [==============================] - 16s 86ms/step - loss: 0.0134 - val_loss: 0.0018\n",
            "Epoch 2/100\n",
            "144/144 [==============================] - 13s 87ms/step - loss: 0.0042 - val_loss: 0.0017\n",
            "Epoch 3/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 0.0033 - val_loss: 0.0015\n",
            "Epoch 4/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 0.0032 - val_loss: 0.0012\n",
            "Epoch 5/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 0.0029 - val_loss: 0.0017\n",
            "Epoch 6/100\n",
            "144/144 [==============================] - 12s 84ms/step - loss: 0.0026 - val_loss: 0.0011\n",
            "Epoch 7/100\n",
            "144/144 [==============================] - 12s 84ms/step - loss: 0.0025 - val_loss: 0.0011\n",
            "Epoch 8/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 0.0023 - val_loss: 0.0013\n",
            "Epoch 9/100\n",
            "144/144 [==============================] - 12s 84ms/step - loss: 0.0023 - val_loss: 0.0015\n",
            "Epoch 10/100\n",
            "144/144 [==============================] - 12s 81ms/step - loss: 0.0020 - val_loss: 0.0012\n",
            "Epoch 11/100\n",
            "144/144 [==============================] - 12s 81ms/step - loss: 0.0019 - val_loss: 0.0011\n",
            "Epoch 12/100\n",
            "144/144 [==============================] - 13s 89ms/step - loss: 0.0017 - val_loss: 0.0011\n",
            "Epoch 13/100\n",
            "144/144 [==============================] - 11s 78ms/step - loss: 0.0017 - val_loss: 9.1037e-04\n",
            "Epoch 14/100\n",
            "144/144 [==============================] - 12s 81ms/step - loss: 0.0016 - val_loss: 9.8378e-04\n",
            "Epoch 15/100\n",
            "144/144 [==============================] - 12s 86ms/step - loss: 0.0015 - val_loss: 9.8857e-04\n",
            "Epoch 16/100\n",
            "144/144 [==============================] - 12s 85ms/step - loss: 0.0015 - val_loss: 0.0011\n",
            "Epoch 17/100\n",
            "144/144 [==============================] - 12s 87ms/step - loss: 0.0015 - val_loss: 8.9184e-04\n",
            "Epoch 18/100\n",
            "144/144 [==============================] - 12s 84ms/step - loss: 0.0014 - val_loss: 8.6683e-04\n",
            "Epoch 19/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 0.0013 - val_loss: 8.9878e-04\n",
            "Epoch 20/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 0.0013 - val_loss: 9.3907e-04\n",
            "Epoch 21/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 0.0013 - val_loss: 8.4019e-04\n",
            "Epoch 22/100\n",
            "144/144 [==============================] - 12s 87ms/step - loss: 0.0013 - val_loss: 7.4328e-04\n",
            "Epoch 23/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 0.0012 - val_loss: 6.8876e-04\n",
            "Epoch 24/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 0.0011 - val_loss: 6.0879e-04\n",
            "Epoch 25/100\n",
            "144/144 [==============================] - 13s 90ms/step - loss: 0.0011 - val_loss: 7.9778e-04\n",
            "Epoch 26/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 0.0011 - val_loss: 5.3807e-04\n",
            "Epoch 27/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 0.0011 - val_loss: 6.4387e-04\n",
            "Epoch 28/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 9.7028e-04 - val_loss: 5.7336e-04\n",
            "Epoch 29/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 8.9794e-04 - val_loss: 5.9603e-04\n",
            "Epoch 30/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 9.1087e-04 - val_loss: 5.2412e-04\n",
            "Epoch 31/100\n",
            "144/144 [==============================] - 11s 78ms/step - loss: 8.6284e-04 - val_loss: 4.2903e-04\n",
            "Epoch 32/100\n",
            "144/144 [==============================] - 11s 78ms/step - loss: 7.4918e-04 - val_loss: 4.8368e-04\n",
            "Epoch 33/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 8.8187e-04 - val_loss: 5.0789e-04\n",
            "Epoch 34/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 8.6541e-04 - val_loss: 5.0279e-04\n",
            "Epoch 35/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 8.0282e-04 - val_loss: 5.6446e-04\n",
            "Epoch 36/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 6.7278e-04 - val_loss: 3.9326e-04\n",
            "Epoch 37/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 7.0585e-04 - val_loss: 3.9423e-04\n",
            "Epoch 38/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 7.8180e-04 - val_loss: 6.0673e-04\n",
            "Epoch 39/100\n",
            "144/144 [==============================] - 13s 91ms/step - loss: 7.5215e-04 - val_loss: 3.8577e-04\n",
            "Epoch 40/100\n",
            "144/144 [==============================] - 12s 84ms/step - loss: 7.7909e-04 - val_loss: 4.6061e-04\n",
            "Epoch 41/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 7.0920e-04 - val_loss: 4.7290e-04\n",
            "Epoch 42/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 6.6278e-04 - val_loss: 3.9951e-04\n",
            "Epoch 43/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 6.3902e-04 - val_loss: 8.4059e-04\n",
            "Epoch 44/100\n",
            "144/144 [==============================] - 12s 84ms/step - loss: 7.1924e-04 - val_loss: 3.0209e-04\n",
            "Epoch 45/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 6.9298e-04 - val_loss: 3.3999e-04\n",
            "Epoch 46/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 6.3158e-04 - val_loss: 3.6266e-04\n",
            "Epoch 47/100\n",
            "144/144 [==============================] - 11s 78ms/step - loss: 6.1218e-04 - val_loss: 3.2330e-04\n",
            "Epoch 48/100\n",
            "144/144 [==============================] - 12s 81ms/step - loss: 6.5079e-04 - val_loss: 3.4367e-04\n",
            "Epoch 49/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 6.0856e-04 - val_loss: 2.9912e-04\n",
            "Epoch 50/100\n",
            "144/144 [==============================] - 12s 84ms/step - loss: 5.4702e-04 - val_loss: 3.9758e-04\n",
            "Epoch 51/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 5.0815e-04 - val_loss: 3.3775e-04\n",
            "Epoch 52/100\n",
            "144/144 [==============================] - 13s 91ms/step - loss: 6.1375e-04 - val_loss: 3.1058e-04\n",
            "Epoch 53/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 6.3273e-04 - val_loss: 3.0713e-04\n",
            "Epoch 54/100\n",
            "144/144 [==============================] - 12s 84ms/step - loss: 5.6267e-04 - val_loss: 3.1460e-04\n",
            "Epoch 55/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 5.3890e-04 - val_loss: 2.8326e-04\n",
            "Epoch 56/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 6.6467e-04 - val_loss: 3.9543e-04\n",
            "Epoch 57/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 5.9193e-04 - val_loss: 4.1197e-04\n",
            "Epoch 58/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 5.8128e-04 - val_loss: 3.2117e-04\n",
            "Epoch 59/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 5.1466e-04 - val_loss: 3.6693e-04\n",
            "Epoch 60/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 6.3030e-04 - val_loss: 3.8112e-04\n",
            "Epoch 61/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 5.1890e-04 - val_loss: 2.8748e-04\n",
            "Epoch 62/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 5.1138e-04 - val_loss: 5.7311e-04\n",
            "Epoch 63/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 5.3504e-04 - val_loss: 3.0503e-04\n",
            "Epoch 64/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 5.3681e-04 - val_loss: 4.9717e-04\n",
            "Epoch 65/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 5.7481e-04 - val_loss: 2.9212e-04\n",
            "Epoch 66/100\n",
            "144/144 [==============================] - 13s 91ms/step - loss: 6.5969e-04 - val_loss: 3.0514e-04\n",
            "Epoch 67/100\n",
            "144/144 [==============================] - 12s 81ms/step - loss: 5.4983e-04 - val_loss: 3.6534e-04\n",
            "Epoch 68/100\n",
            "144/144 [==============================] - 11s 79ms/step - loss: 5.5483e-04 - val_loss: 3.5422e-04\n",
            "Epoch 69/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 5.7798e-04 - val_loss: 2.7998e-04\n",
            "Epoch 70/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 5.5496e-04 - val_loss: 2.8159e-04\n",
            "Epoch 71/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 5.4433e-04 - val_loss: 2.8742e-04\n",
            "Epoch 72/100\n",
            "144/144 [==============================] - 12s 84ms/step - loss: 5.3234e-04 - val_loss: 3.0214e-04\n",
            "Epoch 73/100\n",
            "144/144 [==============================] - 13s 87ms/step - loss: 4.7471e-04 - val_loss: 3.2318e-04\n",
            "Epoch 74/100\n",
            "144/144 [==============================] - 13s 88ms/step - loss: 5.3507e-04 - val_loss: 3.6546e-04\n",
            "Epoch 75/100\n",
            "144/144 [==============================] - 12s 84ms/step - loss: 5.0474e-04 - val_loss: 3.0043e-04\n",
            "Epoch 76/100\n",
            "144/144 [==============================] - 12s 84ms/step - loss: 4.9045e-04 - val_loss: 4.4152e-04\n",
            "Epoch 77/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 5.2518e-04 - val_loss: 2.9819e-04\n",
            "Epoch 78/100\n",
            "144/144 [==============================] - 12s 84ms/step - loss: 5.4888e-04 - val_loss: 2.9652e-04\n",
            "Epoch 79/100\n",
            "144/144 [==============================] - 13s 89ms/step - loss: 5.5449e-04 - val_loss: 2.7661e-04\n",
            "Epoch 80/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 4.7685e-04 - val_loss: 3.0019e-04\n",
            "Epoch 81/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 5.0146e-04 - val_loss: 3.3704e-04\n",
            "Epoch 82/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 5.2276e-04 - val_loss: 3.1137e-04\n",
            "Epoch 83/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 5.6044e-04 - val_loss: 3.2945e-04\n",
            "Epoch 84/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 5.5823e-04 - val_loss: 2.8213e-04\n",
            "Epoch 85/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 5.1975e-04 - val_loss: 2.7711e-04\n",
            "Epoch 86/100\n",
            "144/144 [==============================] - 12s 84ms/step - loss: 4.3641e-04 - val_loss: 3.0003e-04\n",
            "Epoch 87/100\n",
            "144/144 [==============================] - 17s 117ms/step - loss: 5.3908e-04 - val_loss: 3.0672e-04\n",
            "Epoch 88/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 5.7063e-04 - val_loss: 3.0111e-04\n",
            "Epoch 89/100\n",
            "144/144 [==============================] - 12s 85ms/step - loss: 4.7289e-04 - val_loss: 2.7727e-04\n",
            "Epoch 90/100\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 5.2302e-04 - val_loss: 3.5593e-04\n",
            "Epoch 91/100\n",
            "144/144 [==============================] - 13s 91ms/step - loss: 5.0533e-04 - val_loss: 2.7062e-04\n",
            "Epoch 92/100\n",
            "144/144 [==============================] - 11s 80ms/step - loss: 4.8741e-04 - val_loss: 3.3241e-04\n",
            "Epoch 93/100\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 5.4025e-04 - val_loss: 2.6690e-04\n",
            "Epoch 94/100\n",
            "144/144 [==============================] - 14s 99ms/step - loss: 5.2030e-04 - val_loss: 2.8188e-04\n",
            "Epoch 95/100\n",
            "144/144 [==============================] - 18s 126ms/step - loss: 4.7679e-04 - val_loss: 3.2924e-04\n",
            "Epoch 96/100\n",
            "144/144 [==============================] - 13s 93ms/step - loss: 4.8821e-04 - val_loss: 4.2246e-04\n",
            "Epoch 97/100\n",
            "144/144 [==============================] - 13s 89ms/step - loss: 5.2099e-04 - val_loss: 4.1556e-04\n",
            "Epoch 98/100\n",
            "144/144 [==============================] - 13s 88ms/step - loss: 5.5708e-04 - val_loss: 3.1357e-04\n",
            "Epoch 99/100\n",
            "144/144 [==============================] - 12s 86ms/step - loss: 5.5245e-04 - val_loss: 2.8327e-04\n",
            "Epoch 100/100\n",
            "144/144 [==============================] - 12s 84ms/step - loss: 4.9592e-04 - val_loss: 2.9808e-04\n",
            "18/18 [==============================] - 1s 24ms/step\n",
            "Modelin Test R-kare skoru: 0.9420131269252068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Eğitilmiş  modeli  kaydetme\n",
        "save_model(model, 'model9420.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3uSGRMAfrgn",
        "outputId": "6aa5f344-e33d-4021-d48d-68aa9c664e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-e7313819af16>:2: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  save_model(model, 'model9420.h5')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Verileri yükle\n",
        "data = pd.read_excel(\"train.xlsx\")\n",
        "data = data.drop([\"id\", \"temp\", \"w_status\"], axis=1)\n",
        "\n",
        "# 'date' sütununu datetime formatına çevirme\n",
        "data['date_v'] = pd.to_datetime(data['date_v'])\n",
        "\n",
        "# 'date' sütununu Unix zaman damgasına çevirme\n",
        "data['unix_time'] = data['date_v'].apply(lambda x: int((x - datetime(1970, 1, 1)).total_seconds()))\n",
        "\n",
        "# Gereksiz sütunu ve orijinal tarih sütununu kaldırma\n",
        "data = data.drop([\"date_v\"], axis=1)\n",
        "\n",
        "# MinMaxScaler ile 'yukh', 'reg' ve 'power' sütunlarını ölçeklendirme\n",
        "scaler_yukh = MinMaxScaler()\n",
        "scaler_reg = MinMaxScaler()\n",
        "scaler_power = MinMaxScaler()\n",
        "\n",
        "data['yukh_scaled'] = scaler_yukh.fit_transform(data[['yukh']])\n",
        "data['reg_scaled'] = scaler_reg.fit_transform(data[['reg']])\n",
        "data['power_scaled'] = scaler_power.fit_transform(data[['power']])\n",
        "\n",
        "# Ölçeklenmiş sütunları veriden kaldırma\n",
        "data = data.drop([\"yukh\", \"reg\", \"power\"], axis=1)\n",
        "\n",
        "# Zaman serisi formatına dönüştürme\n",
        "def create_time_series_data(data, window_size):\n",
        "    X, y = [], []\n",
        "\n",
        "    for i in range(len(data) - window_size):\n",
        "        # Pencere boyutu kadar veriyi seçme\n",
        "        window_yukh = data['yukh_scaled'][i:i+window_size].values\n",
        "        window_reg = data['reg_scaled'][i:i+window_size].values\n",
        "        window_power = data['power_scaled'][i:i+window_size].values\n",
        "        target = data['yukh_scaled'][i + window_size]\n",
        "\n",
        "        X.append(np.column_stack((window_yukh, window_reg, window_power)))\n",
        "        y.append(target)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Pencere boyutunu belirleme\n",
        "window_size = 64\n",
        "\n",
        "# Giriş ve hedef verilerini oluşturma\n",
        "X, y = create_time_series_data(data, window_size)\n",
        "\n",
        "# Veriyi eğitim ve test setlerine ayırma\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "# Yüklü modeli yükleme\n",
        "loaded_model = load_model('model.h5')\n",
        "\n",
        "# Modeli tekrar eğitme\n",
        "loaded_model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "# Test seti üzerinde tahmin yapma\n",
        "test_predictions = loaded_model.predict(X_test)\n",
        "r2_test = r2_score(y_test, test_predictions)\n",
        "\n",
        "print(f'Modelin Test R-kare skoru: {r2_test}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUrNkeG1afX9",
        "outputId": "74678b86-fe93-4d01-fdc0-65738fb92ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "144/144 [==============================] - 18s 106ms/step - loss: 4.9845e-04 - val_loss: 2.8164e-04\n",
            "Epoch 2/50\n",
            "144/144 [==============================] - 13s 93ms/step - loss: 4.4288e-04 - val_loss: 3.4596e-04\n",
            "Epoch 3/50\n",
            "144/144 [==============================] - 12s 87ms/step - loss: 5.1612e-04 - val_loss: 2.8380e-04\n",
            "Epoch 4/50\n",
            "144/144 [==============================] - 13s 90ms/step - loss: 5.4913e-04 - val_loss: 2.7967e-04\n",
            "Epoch 5/50\n",
            "144/144 [==============================] - 13s 94ms/step - loss: 4.4344e-04 - val_loss: 2.6001e-04\n",
            "Epoch 6/50\n",
            "144/144 [==============================] - 13s 93ms/step - loss: 4.9277e-04 - val_loss: 2.6006e-04\n",
            "Epoch 7/50\n",
            "144/144 [==============================] - 13s 88ms/step - loss: 4.4534e-04 - val_loss: 3.1887e-04\n",
            "Epoch 8/50\n",
            "144/144 [==============================] - 14s 100ms/step - loss: 5.0260e-04 - val_loss: 2.8661e-04\n",
            "Epoch 9/50\n",
            "144/144 [==============================] - 13s 93ms/step - loss: 4.3565e-04 - val_loss: 3.8358e-04\n",
            "Epoch 10/50\n",
            "144/144 [==============================] - 13s 90ms/step - loss: 4.7724e-04 - val_loss: 3.0746e-04\n",
            "Epoch 11/50\n",
            "144/144 [==============================] - 13s 92ms/step - loss: 4.3347e-04 - val_loss: 2.5968e-04\n",
            "Epoch 12/50\n",
            "144/144 [==============================] - 13s 91ms/step - loss: 4.4815e-04 - val_loss: 2.6309e-04\n",
            "Epoch 13/50\n",
            "144/144 [==============================] - 15s 103ms/step - loss: 4.9759e-04 - val_loss: 3.0374e-04\n",
            "Epoch 14/50\n",
            "144/144 [==============================] - 14s 94ms/step - loss: 4.8378e-04 - val_loss: 2.9247e-04\n",
            "Epoch 15/50\n",
            "144/144 [==============================] - 12s 86ms/step - loss: 4.5250e-04 - val_loss: 2.8977e-04\n",
            "Epoch 16/50\n",
            "144/144 [==============================] - 13s 90ms/step - loss: 4.6195e-04 - val_loss: 3.7265e-04\n",
            "Epoch 17/50\n",
            "144/144 [==============================] - 13s 89ms/step - loss: 4.6435e-04 - val_loss: 7.3449e-04\n",
            "Epoch 18/50\n",
            "144/144 [==============================] - 12s 85ms/step - loss: 4.7962e-04 - val_loss: 3.4061e-04\n",
            "Epoch 19/50\n",
            "144/144 [==============================] - 13s 92ms/step - loss: 5.0264e-04 - val_loss: 2.8423e-04\n",
            "Epoch 20/50\n",
            "144/144 [==============================] - 13s 88ms/step - loss: 4.6492e-04 - val_loss: 3.0592e-04\n",
            "Epoch 21/50\n",
            "144/144 [==============================] - 13s 88ms/step - loss: 4.6932e-04 - val_loss: 2.6984e-04\n",
            "Epoch 22/50\n",
            "144/144 [==============================] - 13s 93ms/step - loss: 4.3549e-04 - val_loss: 2.5671e-04\n",
            "Epoch 23/50\n",
            "144/144 [==============================] - 13s 89ms/step - loss: 4.8085e-04 - val_loss: 2.7826e-04\n",
            "Epoch 24/50\n",
            "144/144 [==============================] - 13s 89ms/step - loss: 4.7453e-04 - val_loss: 2.6411e-04\n",
            "Epoch 25/50\n",
            "144/144 [==============================] - 15s 101ms/step - loss: 4.5535e-04 - val_loss: 2.5465e-04\n",
            "Epoch 26/50\n",
            "144/144 [==============================] - 13s 92ms/step - loss: 3.6310e-04 - val_loss: 2.9678e-04\n",
            "Epoch 27/50\n",
            "144/144 [==============================] - 12s 86ms/step - loss: 4.1609e-04 - val_loss: 2.6558e-04\n",
            "Epoch 28/50\n",
            "144/144 [==============================] - 12s 86ms/step - loss: 4.3474e-04 - val_loss: 4.2291e-04\n",
            "Epoch 29/50\n",
            "144/144 [==============================] - 12s 85ms/step - loss: 4.8843e-04 - val_loss: 2.9641e-04\n",
            "Epoch 30/50\n",
            "144/144 [==============================] - 12s 85ms/step - loss: 4.0874e-04 - val_loss: 2.6124e-04\n",
            "Epoch 31/50\n",
            "144/144 [==============================] - 12s 85ms/step - loss: 4.0414e-04 - val_loss: 2.6355e-04\n",
            "Epoch 32/50\n",
            "144/144 [==============================] - 12s 84ms/step - loss: 4.5235e-04 - val_loss: 2.7492e-04\n",
            "Epoch 33/50\n",
            "144/144 [==============================] - 12s 85ms/step - loss: 4.5862e-04 - val_loss: 3.4864e-04\n",
            "Epoch 34/50\n",
            "144/144 [==============================] - 12s 84ms/step - loss: 4.1656e-04 - val_loss: 3.0981e-04\n",
            "Epoch 35/50\n",
            "144/144 [==============================] - 12s 85ms/step - loss: 4.3682e-04 - val_loss: 2.7233e-04\n",
            "Epoch 36/50\n",
            "144/144 [==============================] - 12s 86ms/step - loss: 4.4771e-04 - val_loss: 2.6606e-04\n",
            "Epoch 37/50\n",
            "144/144 [==============================] - 13s 93ms/step - loss: 4.5246e-04 - val_loss: 2.5884e-04\n",
            "Epoch 38/50\n",
            "144/144 [==============================] - 12s 85ms/step - loss: 3.9466e-04 - val_loss: 2.5732e-04\n",
            "Epoch 39/50\n",
            "144/144 [==============================] - 12s 86ms/step - loss: 4.2669e-04 - val_loss: 2.8628e-04\n",
            "Epoch 40/50\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 4.4670e-04 - val_loss: 3.2608e-04\n",
            "Epoch 41/50\n",
            "144/144 [==============================] - 12s 83ms/step - loss: 4.4998e-04 - val_loss: 3.1004e-04\n",
            "Epoch 42/50\n",
            "144/144 [==============================] - 12s 84ms/step - loss: 4.1233e-04 - val_loss: 2.8049e-04\n",
            "Epoch 43/50\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 4.0948e-04 - val_loss: 4.2560e-04\n",
            "Epoch 44/50\n",
            "144/144 [==============================] - 12s 82ms/step - loss: 5.0104e-04 - val_loss: 2.9704e-04\n",
            "Epoch 45/50\n",
            "144/144 [==============================] - 12s 85ms/step - loss: 4.4276e-04 - val_loss: 2.9285e-04\n",
            "Epoch 46/50\n",
            "144/144 [==============================] - 12s 86ms/step - loss: 4.2157e-04 - val_loss: 3.5717e-04\n",
            "Epoch 47/50\n",
            "144/144 [==============================] - 13s 89ms/step - loss: 4.6445e-04 - val_loss: 2.6954e-04\n",
            "Epoch 48/50\n",
            "144/144 [==============================] - 12s 85ms/step - loss: 4.4403e-04 - val_loss: 2.7979e-04\n",
            "Epoch 49/50\n",
            "144/144 [==============================] - 13s 92ms/step - loss: 4.1635e-04 - val_loss: 3.3132e-04\n",
            "Epoch 50/50\n",
            "144/144 [==============================] - 12s 85ms/step - loss: 4.1885e-04 - val_loss: 2.6634e-04\n",
            "18/18 [==============================] - 1s 26ms/step\n",
            "Modelin Test R-kare skoru: 0.9481868933381028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Eğitilmiş  modeli  kaydetme\n",
        "save_model(loaded_model, 'model9481.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjsFFdDg8r0U",
        "outputId": "52254ffc-edf4-427d-be3b-784faf8de2c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-800e174dfaed>:2: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  save_model(loaded_model, 'model9481.h5')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from keras.models import load_model\n",
        "\n",
        "# Veriyi yükleme ve gereksiz sütunları kaldırma\n",
        "data = pd.read_excel(\"test.xlsx\")\n",
        "data = data.drop([\"id\", \"temp\", \"w_status\"], axis=1)\n",
        "\n",
        "data = data[(data != 0).all(axis=1)]  # Tüm sütunlar için 0 olmayan satırları seçme\n",
        "data = data.dropna()  # NaN değerleri içeren satırları kaldırma\n",
        "\n",
        "# 'date' sütununu datetime formatına çevirme\n",
        "data['date_v'] = pd.to_datetime(data['date_v'])\n",
        "\n",
        "# 'date' sütununu Unix zaman damgasına çevirme\n",
        "data['unix_time'] = data['date_v'].apply(lambda x: int((x - datetime(1970, 1, 1)).total_seconds()))\n",
        "\n",
        "# Gereksiz sütunu ve orijinal tarih sütununu kaldırma\n",
        "data = data.drop([\"date_v\"], axis=1)\n",
        "\n",
        "# MinMaxScaler ile 'yukh', 'reg' ve 'power' sütunlarını ölçeklendirme\n",
        "scaler_yukh = MinMaxScaler()\n",
        "scaler_reg = MinMaxScaler()\n",
        "scaler_power = MinMaxScaler()\n",
        "\n",
        "data['yukh_scaled'] = scaler_yukh.fit_transform(data[['yukh']])\n",
        "data['reg_scaled'] = scaler_reg.fit_transform(data[['reg']])\n",
        "data['power_scaled'] = scaler_power.fit_transform(data[['power']])\n",
        "\n",
        "# Ölçeklenmiş sütunları veriden kaldırma\n",
        "data = data.drop([\"yukh\", \"reg\", \"power\"], axis=1)\n",
        "\n",
        "# Zaman serisi formatına dönüştürme\n",
        "def create_time_series_data(data, window_size):\n",
        "    X, y = [], []\n",
        "\n",
        "    for i in range(len(data) - window_size):\n",
        "        # Pencere boyutu kadar veriyi seçme\n",
        "        window_yukh = data['yukh_scaled'][i:i+window_size].values\n",
        "        window_reg = data['reg_scaled'][i:i+window_size].values\n",
        "        window_power = data['power_scaled'][i:i+window_size].values\n",
        "        target = data['yukh_scaled'][i: i + window_size]\n",
        "\n",
        "        X.append(np.column_stack((window_yukh, window_reg, window_power)))\n",
        "        y.append(target)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Pencere boyutunu belirleme (aynı boyutu kullanmalısınız)\n",
        "window_size = 64\n",
        "\n",
        "# Giriş ve hedef verilerini oluşturma\n",
        "X, y = create_time_series_data(data, window_size)\n",
        "\n",
        "# Modeli yükleme\n",
        "model = load_model('model9481.h5')\n",
        "\n",
        "# Test seti üzerinde tahmin yapma\n",
        "test_predictions = model.predict(X)\n",
        "\n",
        "# Test setindeki pencere boyutunda son gerçek değerler\n",
        "y_true = y[:, -1]\n",
        "\n",
        "# Test setindeki pencere boyutunda son tahminler\n",
        "y_pred = test_predictions[:, -1]\n",
        "\n",
        "# R-kare skoru hesaplama\n",
        "r2_test = r2_score(y_true, y_pred)\n",
        "\n",
        "print(f'Modelin Test R-kare skoru: {r2_test}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv7x6qyL8Ek0",
        "outputId": "96a28a85-af95-4ef2-9e9a-dd71db82ff21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 2s 36ms/step\n",
            "Modelin Test R-kare skoru: 0.9739492825054626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerçek 'yukh' değerlerini al\n",
        "yukh_original = scaler_yukh.inverse_transform(y[:, -1].reshape(-1, 1)).flatten()\n",
        "\n",
        "# Tahmin edilen 'yukh' değerlerini ölçeklendirmeyi tersine çevirme\n",
        "predicted_yukh_original = scaler_yukh.inverse_transform(test_predictions[:, -1].reshape(-1, 1)).flatten()\n",
        "\n",
        "# Uzunlukları kontrol et\n",
        "print(len(yukh_original), len(predicted_yukh_original))\n",
        "\n",
        "# Veri çerçevesi oluşturma\n",
        "result_df = pd.DataFrame({'Gerçek Yukh': yukh_original, 'Tahmin Yukh': predicted_yukh_original})\n",
        "\n",
        "# Sonuçları ekrana yazdırma\n",
        "print(result_df)\n",
        "\n",
        "# Veriyi Excel dosyasına yazma\n",
        "result_df.to_excel(\"gercek_tahmin_yukh1.xlsx\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHVu02XB8UOy",
        "outputId": "d48cc6a6-693e-47c5-b9eb-b4732265a319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "812 812\n",
            "     Gerçek Yukh  Tahmin Yukh\n",
            "0         6047.0  6047.085449\n",
            "1         6044.0  6045.154297\n",
            "2         6045.0  6045.241699\n",
            "3         6046.0  6045.894043\n",
            "4         6043.0  6044.343262\n",
            "..           ...          ...\n",
            "807       6007.0  6007.411133\n",
            "808       6006.0  6004.934082\n",
            "809       6005.0  6003.037109\n",
            "810       6004.0  6002.067383\n",
            "811       6005.0  6002.730469\n",
            "\n",
            "[812 rows x 2 columns]\n"
          ]
        }
      ]
    }
  ]
}